{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "480a03cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import joblib\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f848ac1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"latestdataset.csv\")\n",
    "df.drop(columns=[\"rain (mm)\", \"precipitation (mm)\", \"soil_moisture_0_to_7cm (m³/m³)\"], inplace=True)\n",
    "df['time'] = pd.to_datetime(df['time'])\n",
    "df = df.set_index('time')\n",
    "df = df.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5655faf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krati\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:432: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# ---------- Load Scaler ----------\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = joblib.load(\"scaler.pkl\")  \n",
    "df_scaled = pd.DataFrame(scaler.transform(df), index=df.index, columns=df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "857905e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sequences\n",
    "\n",
    "lookback = 48\n",
    "horizon = 6\n",
    "n_features = df_scaled.shape[1]\n",
    "\n",
    "def create_sequences(data, lookback=48, horizon=6):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - lookback - horizon + 1):\n",
    "        X.append(data[i:i+lookback])\n",
    "        y.append(data[i+lookback:i+lookback+horizon])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "X, y = create_sequences(df_scaled.values, lookback, horizon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "245a3d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test val split\n",
    "\n",
    "n = len(X)\n",
    "train_idx = int(0.7 * n)\n",
    "val_idx   = int(0.85 * n)\n",
    "\n",
    "X_train, y_train = X[:train_idx], y[:train_idx]\n",
    "X_val, y_val     = X[train_idx:val_idx], y[train_idx:val_idx]\n",
    "X_test, y_test   = X[val_idx:], y[val_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "84ca2724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten for XGBoost\n",
    "X_val_flat  = X_val.reshape((X_val.shape[0], -1))\n",
    "X_test_flat = X_test.reshape((X_test.shape[0], -1))\n",
    "y_val_flat  = y_val.reshape((y_val.shape[0], -1))\n",
    "y_test_flat = y_test.reshape((y_test.shape[0], -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7134a942",
   "metadata": {},
   "source": [
    "# -------------------------------\n",
    "# 1. Load models\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3797e901",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model = load_model(\"best_lstm.keras\")\n",
    "gru_model  = load_model(\"best_gru.keras\")\n",
    "xgb_model  = joblib.load(\"xgb_multi_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75cb74c",
   "metadata": {},
   "source": [
    "# -------------------------------\n",
    "# 2. Prepare validation data\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9c2e2955",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = X_val.shape[2]\n",
    "horizon = y_val.shape[1]\n",
    "\n",
    "X_val_flat = X_val.reshape((X_val.shape[0], -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e39f548",
   "metadata": {},
   "source": [
    "# -------------------------------\n",
    "# 3. Base model predictions on validation set\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6fa3ab98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step\n"
     ]
    }
   ],
   "source": [
    "X_val_fixed = X_val[:, -48:, :]\n",
    "X_test_fixed = X_test[:, -48:, :]\n",
    "y_val_lstm = lstm_model.predict(X_val_fixed).reshape(X_val_fixed.shape[0], -1)\n",
    "y_val_gru  = gru_model.predict(X_val_fixed).reshape(X_val_fixed.shape[0], -1)\n",
    "y_val_xgb  = xgb_model.predict(X_val_flat)\n",
    "\n",
    "# Stack base model predictions\n",
    "X_meta = np.concatenate([y_val_lstm, y_val_gru, y_val_xgb], axis=1)\n",
    "y_meta = y_val.reshape(X_val.shape[0], -1)  # flatten target for meta-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6b3cfe4f-1ab1-4a60-8af7-0f1fb350d9fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_val_lstm.shape: (13146, 24)\n",
      "y_val_gru.shape: (13146, 24)\n",
      "y_val_xgb.shape: (13146, 24)\n",
      "X_meta.shape (to be fed to meta_model): (13146, 72)\n",
      "Meta-model trained input size: (24, 72)\n"
     ]
    }
   ],
   "source": [
    "print(\"y_val_lstm.shape:\", y_val_lstm.shape)\n",
    "print(\"y_val_gru.shape:\", y_val_gru.shape)\n",
    "print(\"y_val_xgb.shape:\", y_val_xgb.shape)\n",
    "print(\"X_meta.shape (to be fed to meta_model):\", X_meta.shape)\n",
    "print(\"Meta-model trained input size:\", getattr(meta_model, \"coef_\", np.zeros((1,))).shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808a84cd",
   "metadata": {},
   "source": [
    "# -------------------------------\n",
    "# 4. Train meta-model\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9aae4d90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['meta_model.pkl']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_meta = np.concatenate([y_val_lstm, y_val_gru, y_val_xgb], axis=1)\n",
    "y_meta = y_val.reshape(X_val.shape[0], -1)  # same as before\n",
    "\n",
    "meta_model = Ridge(alpha=1.0)\n",
    "meta_model.fit(X_meta, y_meta)\n",
    "joblib.dump(meta_model, 'meta_model.pkl')  # Save new meta_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c41424",
   "metadata": {},
   "source": [
    "# -------------------------------\n",
    "# 5. Prepare test set predictions\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cf0b1649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step\n"
     ]
    }
   ],
   "source": [
    "X_test_flat = X_test.reshape((X_test.shape[0], -1))\n",
    "\n",
    "y_test_lstm = lstm_model.predict(X_test_fixed).reshape(X_test_fixed.shape[0], -1)\n",
    "y_test_gru  = gru_model.predict(X_test_fixed).reshape(X_test_fixed.shape[0], -1)\n",
    "y_test_xgb  = xgb_model.predict(X_test_flat)\n",
    "\n",
    "X_test_meta = np.concatenate([y_test_lstm, y_test_gru, y_test_xgb], axis=1)\n",
    "\n",
    "# Final stacked predictions\n",
    "y_pred_stacked = meta_model.predict(X_test_meta)\n",
    "y_pred_stacked = y_pred_stacked.reshape((X_test.shape[0], horizon, n_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128454b7",
   "metadata": {},
   "source": [
    "# -------------------------------\n",
    "# 6. Evaluate stacked predictions\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "32f4bef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.columns.tolist()\n",
    "\n",
    "results = {}\n",
    "avg_results = {}\n",
    "\n",
    "for f_idx, feature in enumerate(features):\n",
    "    results[feature] = {}\n",
    "    mae_list, rmse_list, r2_list = [], [], []\n",
    "    for h in range(horizon):\n",
    "        yt = y_test[:, h, f_idx]\n",
    "        yp = y_pred_stacked[:, h, f_idx]\n",
    "\n",
    "        mae  = mean_absolute_error(yt, yp)\n",
    "        rmse = np.sqrt(mean_squared_error(yt, yp))\n",
    "        r2   = r2_score(yt, yp)\n",
    "\n",
    "        results[feature][f\"Horizon_{h+1}\"] = {\"MAE\": mae, \"RMSE\": rmse, \"R2\": r2}\n",
    "\n",
    "        mae_list.append(mae)\n",
    "        rmse_list.append(rmse)\n",
    "        r2_list.append(r2)\n",
    "\n",
    "    avg_results[feature] = {\n",
    "        \"MAE\": np.mean(mae_list),\n",
    "        \"RMSE\": np.mean(rmse_list),\n",
    "        \"R2\": np.mean(r2_list)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6f81f5",
   "metadata": {},
   "source": [
    "# -------------------------------\n",
    "# 7. Show results in tabular form\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e08f9242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Stacking Ensemble Metrics per Feature & Horizon =====\n",
      "                           Feature    Horizon       MAE      RMSE        R2\n",
      "0              temperature_2m (°C)  Horizon_1  0.013808  0.021290  0.979503\n",
      "1              temperature_2m (°C)  Horizon_2  0.018646  0.026886  0.967319\n",
      "2              temperature_2m (°C)  Horizon_3  0.021508  0.030355  0.958348\n",
      "3              temperature_2m (°C)  Horizon_4  0.023126  0.032317  0.952802\n",
      "4              temperature_2m (°C)  Horizon_5  0.024323  0.033723  0.948620\n",
      "5              temperature_2m (°C)  Horizon_6  0.025398  0.034917  0.944935\n",
      "6         relative_humidity_2m (%)  Horizon_1  0.023691  0.036299  0.975029\n",
      "7         relative_humidity_2m (%)  Horizon_2  0.033845  0.048199  0.955973\n",
      "8         relative_humidity_2m (%)  Horizon_3  0.040074  0.055884  0.940817\n",
      "9         relative_humidity_2m (%)  Horizon_4  0.044133  0.060882  0.929761\n",
      "10        relative_humidity_2m (%)  Horizon_5  0.047012  0.064515  0.921139\n",
      "11        relative_humidity_2m (%)  Horizon_6  0.049044  0.067105  0.914690\n",
      "12           wind_speed_10m (km/h)  Horizon_1  0.037580  0.052783  0.855936\n",
      "13           wind_speed_10m (km/h)  Horizon_2  0.047147  0.062881  0.795527\n",
      "14           wind_speed_10m (km/h)  Horizon_3  0.051087  0.066914  0.768457\n",
      "15           wind_speed_10m (km/h)  Horizon_4  0.053539  0.069766  0.748282\n",
      "16           wind_speed_10m (km/h)  Horizon_5  0.055129  0.071575  0.734990\n",
      "17           wind_speed_10m (km/h)  Horizon_6  0.056109  0.072687  0.726647\n",
      "18  soil_temperature_0_to_7cm (°C)  Horizon_1  0.009199  0.013409  0.991423\n",
      "19  soil_temperature_0_to_7cm (°C)  Horizon_2  0.011787  0.016496  0.987020\n",
      "20  soil_temperature_0_to_7cm (°C)  Horizon_3  0.014352  0.019673  0.981541\n",
      "21  soil_temperature_0_to_7cm (°C)  Horizon_4  0.015903  0.021807  0.977322\n",
      "22  soil_temperature_0_to_7cm (°C)  Horizon_5  0.017258  0.023491  0.973688\n",
      "23  soil_temperature_0_to_7cm (°C)  Horizon_6  0.018464  0.025208  0.969706\n",
      "\n",
      "===== Stacking Ensemble Average Metrics per Feature =====\n",
      "                          Feature       MAE      RMSE        R2\n",
      "0             temperature_2m (°C)  0.021135  0.029915  0.958588\n",
      "1        relative_humidity_2m (%)  0.039633  0.055481  0.939568\n",
      "2           wind_speed_10m (km/h)  0.050099  0.066101  0.771640\n",
      "3  soil_temperature_0_to_7cm (°C)  0.014494  0.020014  0.980117\n"
     ]
    }
   ],
   "source": [
    "# Per feature & horizon\n",
    "rows = []\n",
    "for feat, horizons in results.items():\n",
    "    for h, metrics in horizons.items():\n",
    "        row = {\"Feature\": feat, \"Horizon\": h}\n",
    "        row.update(metrics)\n",
    "        rows.append(row)\n",
    "\n",
    "results_df = pd.DataFrame(rows)\n",
    "print(\"\\n===== Stacking Ensemble Metrics per Feature & Horizon =====\")\n",
    "print(results_df)\n",
    "\n",
    "# Average per feature\n",
    "avg_df = pd.DataFrame(avg_results).T.reset_index().rename(columns={\"index\":\"Feature\"})\n",
    "print(\"\\n===== Stacking Ensemble Average Metrics per Feature =====\")\n",
    "print(avg_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3924225",
   "metadata": {},
   "source": [
    "# -------------------------------\n",
    "# 8. Save stacked model for later use\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c0500d2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'joblib.dump({\\n    \"meta_model\": meta_model,\\n    \"lstm_model\": lstm_model,\\n    \"gru_model\": gru_model,\\n    \"xgb_model\": xgb_model\\n}, \"stacked_ensemble.pkl\")\\nprint(\"✅ Stacked ensemble saved as \\'stacked_ensemble.pkl\\'\")'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"joblib.dump({\n",
    "    \"meta_model\": meta_model,\n",
    "    \"lstm_model\": lstm_model,\n",
    "    \"gru_model\": gru_model,\n",
    "    \"xgb_model\": xgb_model\n",
    "}, \"stacked_ensemble.pkl\")\n",
    "print(\"✅ Stacked ensemble saved as 'stacked_ensemble.pkl'\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bd0ad913-39a3-47a6-a22f-ec97fce9d9e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'joblib.dump({\\n    \"meta_model\": meta_model,\\n    \"xgb_model\": xgb_model\\n}, \"stacked_ensemble.pkl\")\\nprint(\"✅ Stacked ensemble saved (without pickling Keras models)\")'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save only meta-model + XGBoost, not Keras models\n",
    "\"\"\"joblib.dump({\n",
    "    \"meta_model\": meta_model,\n",
    "    \"xgb_model\": xgb_model\n",
    "}, \"stacked_ensemble.pkl\")\n",
    "print(\"✅ Stacked ensemble saved (without pickling Keras models)\")\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7ae17edd-da66-47d7-b954-5add1d1b6732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ stacked_pipeline.pkl saved (contains meta_model, xgb, scaler and metadata)\n",
      "✅ Keras models saved: best_lstm.keras, best_gru.keras\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# meta_model and xgb_model should already be defined from your training cell\n",
    "pipeline = {\n",
    "    \"meta_model\": meta_model,     # sklearn Ridge\n",
    "    \"xgb_model\": xgb_model,       # joblib XGBoost model\n",
    "    \"scaler\": scaler,             # MinMaxScaler used for training\n",
    "    \"features\": df.columns.tolist(),  # feature order\n",
    "    \"look_back\": lookback,\n",
    "    \"horizon\": horizon\n",
    "}\n",
    "\n",
    "joblib.dump(pipeline, \"stacked_pipeline.pkl\")\n",
    "print(\"✅ stacked_pipeline.pkl saved (contains meta_model, xgb, scaler and metadata)\")\n",
    "# Ensure Keras models are saved (you already have these lines in your notebook)\n",
    "lstm_model.save(\"best_lstm.keras\")\n",
    "gru_model.save(\"best_gru.keras\")\n",
    "print(\"✅ Keras models saved: best_lstm.keras, best_gru.keras\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144870e2-604b-4724-8db2-93082062fbfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "30d8ee55-44df-48fd-8a62-9b06a10340e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved = joblib.load(\"stacked_ensemble.pkl\")\n",
    "meta_model = saved[\"meta_model\"]\n",
    "xgb_model  = saved[\"xgb_model\"]\n",
    "\n",
    "# Now you can do:\n",
    "# y_pred_xgb = xgb_model.predict(X_input_flat)\n",
    "# y_pred_stacked = meta_model.predict(X_meta_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ffd87df9-8645-4a6c-98b4-5c4a0d14c4a0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pickle' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstacked_ensemble.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m----> 2\u001b[0m     model_dict \u001b[38;5;241m=\u001b[39m \u001b[43mpickle\u001b[49m\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Extract the trained ensemble model\u001b[39;00m\n\u001b[0;32m      5\u001b[0m model \u001b[38;5;241m=\u001b[39m model_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmeta_model\u001b[39m\u001b[38;5;124m'\u001b[39m]   \u001b[38;5;66;03m# or whatever key you used\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pickle' is not defined"
     ]
    }
   ],
   "source": [
    "with open('stacked_ensemble.pkl', 'rb') as f:\n",
    "    model_dict = pickle.load(f)\n",
    "\n",
    "# Extract the trained ensemble model\n",
    "model = model_dict['meta_model']   # or whatever key you used\n",
    "\n",
    "# Then use it normally\n",
    "y_pred = model.predict(X_input).reshape(horizon, len(FEATURES))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1b1c507d-5d72-490d-a41c-8f29c19f56ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 48, 4)\n",
      "GRU expected input shape: (None, 48, 4)\n",
      "X_val shape: (13146, 48, 4)\n"
     ]
    }
   ],
   "source": [
    "print(lstm_model.input_shape)  # Should print (None, 48, 4)\n",
    "print(\"GRU expected input shape:\", gru_model.input_shape) \n",
    "print(\"X_val shape:\", X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afd5c82-4d80-4a0b-a8c6-19bd2b5d2599",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
